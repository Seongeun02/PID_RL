{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CSTRenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperpararameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "lr_mu        = 0.0005\n",
    "lr_q         = 0.001\n",
    "gamma        = 0.99\n",
    "batch_size   = 32\n",
    "buffer_limit = 50000\n",
    "tau          = 0.005 # for target network soft update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "\n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "    \n",
    "    def sample(self, n):\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "\n",
    "        for transition in mini_batch:\n",
    "            s, a, r, s_prime, done = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append(a)\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask = 0.0 if done else 1.0 \n",
    "            done_mask_lst.append([done_mask])\n",
    "        \n",
    "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst, dtype=torch.float), \\\n",
    "                torch.tensor(r_lst, dtype=torch.float), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
    "                torch.tensor(done_mask_lst, dtype=torch.float)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actor critic network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MuNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc_mu = nn.Linear(64, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        mu = torch.tanh(self.fc_mu(x))  # range [-1,1]\n",
    "        return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QNet, self).__init__()\n",
    "        self.fc_s = nn.Linear(3, 64)\n",
    "        self.fc_a = nn.Linear(3,64)\n",
    "        self.fc_q = nn.Linear(128, 32)\n",
    "        self.fc_out = nn.Linear(32,1)\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        h1 = F.relu(self.fc_s(x))\n",
    "        h2 = F.relu(self.fc_a(a))\n",
    "        cat = torch.cat([h1,h2], dim=1)\n",
    "        q = F.relu(self.fc_q(cat))\n",
    "        q = self.fc_out(q)\n",
    "        return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrnsteinUhlenbeckNoise:\n",
    "    def __init__(self, mu):\n",
    "        self.theta, self.dt, self.sigma = 0.1, 0.01, 0.1\n",
    "        self.mu = mu\n",
    "        self.x_prev = np.zeros_like(self.mu)\n",
    "\n",
    "    def __call__(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\n",
    "                self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\n",
    "        self.x_prev = x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mu, mu_target, q, q_target, memory, q_optimizer, mu_optimizer):\n",
    "    s,a,r,s_prime,done_mask  = memory.sample(batch_size)\n",
    "    \n",
    "    target = r + gamma * q_target(s_prime, mu_target(s_prime)) * done_mask\n",
    "    q_loss = F.smooth_l1_loss(q(s,a), target.detach())\n",
    "    q_optimizer.zero_grad()\n",
    "    q_loss.backward()\n",
    "    q_optimizer.step()\n",
    "    \n",
    "    mu_loss = -q(s,mu(s)).mean() # That's all for the policy loss.\n",
    "    mu_optimizer.zero_grad()\n",
    "    mu_loss.backward()\n",
    "    mu_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_update(net, net_target):\n",
    "    for param_target, param in zip(net_target.parameters(), net.parameters()):\n",
    "        param_target.data.copy_(param_target.data * (1.0 - tau) + param.data * tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    env = CSTRenv.CSTRenv()\n",
    "    memory = ReplayBuffer()\n",
    "\n",
    "    q, q_target = QNet(), QNet()\n",
    "    q_target.load_state_dict(q.state_dict())\n",
    "    mu, mu_target = MuNet(), MuNet()\n",
    "    mu_target.load_state_dict(mu.state_dict())\n",
    "\n",
    "    score = []\n",
    "    print_interval = 20\n",
    "\n",
    "    mu_optimizer = optim.Adam(mu.parameters(), lr=lr_mu)\n",
    "    q_optimizer  = optim.Adam(q.parameters(), lr=lr_q)\n",
    "    ou_noise = OrnsteinUhlenbeckNoise(mu=np.zeros(1))\n",
    "\n",
    "    for n_epi in range(10000):\n",
    "        s = env.reset()  # initial state\n",
    "        done = False\n",
    "\n",
    "        count = 0\n",
    "        while count < 200 and not done:\n",
    "            a = mu(torch.from_numpy(np.array(s)).float()) \n",
    "            a = [a[i].item() + ou_noise()[0] for i in range(len(a))]\n",
    "            s_prime, r, done, _ = env.step(a)\n",
    "            memory.put((s,a,r/100.0,s_prime,done))\n",
    "            score.append(r)\n",
    "            s = s_prime\n",
    "            count += 1\n",
    "                \n",
    "        if memory.size()>2000:\n",
    "            for i in range(10):\n",
    "                train(mu, mu_target, q, q_target, memory, q_optimizer, mu_optimizer)\n",
    "                soft_update(mu, mu_target)\n",
    "                soft_update(q,  q_target)\n",
    "        \n",
    "        if n_epi%print_interval==0 and n_epi!=0:\n",
    "            print(\"# of episode :{}, avg score : {:.1f}\".format(n_epi, sum(score[count-print_interval:count])/print_interval))\n",
    "\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
